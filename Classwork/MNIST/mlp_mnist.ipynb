{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Part 1\n",
    "---\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    "    1. MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    "\n",
    "    2. Normalize data by rescaling them to (0,1)\n",
    "\n",
    "    3. Convert label arrays to 1-hot representation (keras.utils.to_categorical)\n",
    "\n",
    "    4. Define Model\n",
    "\n",
    "        - Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "        - Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "        - Output Layer: Fully Connected + Softmax Activition\n",
    "\n",
    "- Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Packages \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting the digit image\n",
    "%matplotlib inline  \n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the random image and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n"
     ]
    }
   ],
   "source": [
    "rand_num = np.random.randint(60000)\n",
    "\n",
    "plt.imshow(X_train[rand_num], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# print its label\n",
    "print('label:', y_train[rand_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network accept 1D data. So we need to flatten our 2D image, then print the dimension of the result arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Normalizing, one-hot-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the data \n",
    "# NOTE: when data is big it is better to do reshaping and normalinzing inplace, bc copying the opject takes up a lot\n",
    "# of memory space\n",
    "NUM_CLASSES = 10\n",
    "X_train = np.reshape(X_train, [-1, 28*28]).astype('float32')\n",
    "X_test = np.reshape(X_test, [-1, 28*28]).astype('float32')\n",
    "\n",
    "# Normalize data by rescaling them to (0,1)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert label arrays to 1-hot representation\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the following layers to the network:\n",
    "\n",
    "- Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "- Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "- Outout Layer: Fully Connected + Softmax Activition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "# Add the layers to model here.\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer=RandomNormal(0,0.01)))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer=RandomNormal(0,0.01)))\n",
    "# Output Layer: Fully Connected + Softmax Activition\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine loss function, optimizer and metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.3054 - acc: 0.9051 - val_loss: 0.1449 - val_acc: 0.9549\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.1024 - acc: 0.9688 - val_loss: 0.0860 - val_acc: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0662 - acc: 0.9797 - val_loss: 0.0785 - val_acc: 0.9779\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0487 - acc: 0.9852 - val_loss: 0.0796 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0368 - acc: 0.9887 - val_loss: 0.0765 - val_acc: 0.9814\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.0820 - val_acc: 0.9835\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0894 - val_acc: 0.9809\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0196 - acc: 0.9944 - val_loss: 0.0943 - val_acc: 0.9790\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0856 - val_acc: 0.9836\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0142 - acc: 0.9958 - val_loss: 0.1071 - val_acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb31fa3400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the review of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
